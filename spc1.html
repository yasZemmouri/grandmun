<!-- Grandmun  -->
<!DOCTYPE html>
<html lang="en">

<head>
    <title>Grandmun - index</title>
    <!--===== Meta =====-->
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Debate Event for high school students at [school name]">
    <!--===== Favicons =====-->
    <link rel="icon" type="image/x-icon" href="img/favicon-32.ico">
    <link rel="apple-touch-icon" href="img/favicon-180.png">
    <!--===== Fonts =====-->
    <!-- bootstrap icons -->
    <!-- we can also use them locally  -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.10.2/font/bootstrap-icons.css">
    <!--===== Style =====-->
    <!-- Vendor CSS Files -->
    <link href="assets/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
    <!-- Main CSS File -->
    <link href="assets/css/main.css" rel="stylesheet">
    <!-- countdown2 dependencies -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.3/jquery.min.js"></script>
    <script src="jquery.min.js"></script>
    <script src="jquery-ui/jquery-ui.js"></script>
    <script src="TweenMax.min.js"></script>
    <script src="TimelineMax.min.js"></script>
</head>

<body>
    <header class="d-flex align-items-center">
        <div class="container-xl d-flex align-items-center justify-content-between">
            <a href="/">
                <h1>grandmun</h1>
            </a>
            <!-- what's mobile-nav-toggle class? -->
            <!-- mobile-nav-toggle is for javascript. I give it to nav-show and nav-hide so it allows me to put them both in one eventListner -->
            <i class="mobile-nav-toggle mobile-nav-show bi bi-list"></i>
            <i class="mobile-nav-toggle mobile-nav-hide d-none  bi bi-x"></i>
            <nav class="navbar">
                <ul>
                    <li><a href="index.html">Home</a></li>
                    <li><a href="faq.html">FAQ</a></li>
                    <li><a href="senegal.html">senegal project</a></li>
                    <li><a href="">delegate guides</a></li>
                    <li class="dropdown"><a href="#"><span>Committees</span> <i
                                class="bi bi-chevron-down dropdown-indicator"></i></a>
                        <ul>
                            <li><a href="#ecosoc">ECOSOC</a></li>
                            <!-- <li class="dropdown"><a href="#"><span>Deep Dropdown</span> <i
                                        class="bi bi-chevron-down dropdown-indicator"></i></a>
                                <ul>
                                    <li><a href="#">Deep Dropdown 1</a></li>
                                    <li><a href="#">Deep Dropdown 2</a></li>
                                    <li><a href="#">Deep Dropdown 3</a></li>
                                    <li><a href="#">Deep Dropdown 4</a></li>
                                    <li><a href="#">Deep Dropdown 5</a></li>
                                </ul>
                            </li> -->
                            <li><a href="spc1.html" class="active">SPC 1</a></li>
                            <li><a href="spc2.html">SPC 2</a></li>
                            <li><a href="hrc.html">HRC</a></li>
                        </ul>
                    </li>
                    <li><a href="apply.html">apply</a></li>
                </ul>
            </nav>
        </div>
    </header><!-- End Header -->
    <main id="spc1">
        <!-- =======  ======= -->
        <article id=>
            <div class='container-xl'>
                <h1>Special Conference1<span>The Militarization of Artificial Intelligence</span></h1>
            </div>
            <!-- ======= intro ======= -->
            <section id="intro">
                <div class='container-xl'>
                    <h2>Introduction</h2>
                    <p> The rapid pace at which technology advances today is, in many ways, a double-edged sword. The
                        21st century has seen many controversial technological and scientific debates draw worldwide
                        attention - none of which are more relevant than artificial intelligence. Perhaps the most
                        potentially limitless tool in mankind’s arsenal, AI’s existence poses both a threat and
                        opportunity to humanity, and it’s critical that its usage is approached with the utmost caution
                        and open-mindedness. Although we seem to be a step away from seeing androids capable of true
                        independent thought, artificial intelligence is no longer a far-off concept, and it’s critical
                        to erase the belief that it is. Today, AI in many forms is used to perform tasks more
                        efficiently and fervently than any human could. Social media uses AI algorithms to personalize
                        advertisements based on the user’s online activity. In the healthcare sector, machines capable
                        of diagnosing patients see a large degree of success. Tech giants such as Google and Microsoft
                        own functioning facial recognition tools. Furthermore, innovations such as autonomous cars and
                        capable digital assistants are on the front page every other day. However, AI can be equally
                        deadly as it is productive - if not more - when used in the wrong ways. The questionable and
                        unregulated application of AI into the battlefield is a topic which concerns the very near
                        future of warfare. In 2017, Harvard’s Belfer Center predicted that Artificial Intelligence may
                        be as transformative to common warfare as nuclear weaponry and even weaponized aircraft.
                        Internationally, there is huge interest and funding in R&D regarding the militarization of AI.
                        Fiscal reports for 2022 have shown $874 million in funding allocated to ‘artificial intelligence
                        projects’ by the US Department of Defense. Furthermore, a recent study by the Georgetown
                        University Center for Security and Emerging Technology reported that the People’s Liberation
                        Army (PLA) of China spends an average of $1.6 billion on AI-related projects. In his 2018 agenda
                        on disarmament, Securing Our Common Future, Secretary General António Guterres stated that,
                        “Arms control has always been motivated by the need to keep ahead of the challenges to peace and
                        security raised by science and technology.” AI is here now, there’s no question about it. As
                        recently as June 2022, China’s Sunway supercomputer AI ran 174 trillion parameters - rivalling
                        the capacity of our own human brain. It’s of the utmost importance that we race against the
                        rapid development of AI to plan for potential issues, and protect those involved from the great
                        threat to peace AI could pose - if used in the wrong ways. </p>
                    <p>Perhaps the most troubling prospect is the possibility of a new global arms race in which the
                        U.S., China, Russia, Iran, Israel, the European Union and others rush to develop fully
                        autonomous drones. The U.S. Air Force is already testing an AI-controlled fighter jet.</p>
                </div>
            </section>
            <!-- ======= Key Terms ======= -->
            <section id=key-terms>
                <div class='container-xl'>
                    <h2>Key Terms</h2>
                    <h3>Narrow AI vs Artificial General Intelligence (AGI)</h3>
                    <p>Artificial Intelligence is an umbrella term which encompasses a vast branch of computer science,
                        concerned with the creation and development of machinery capable of replicating human behavior
                        and intelligence. AI can be generally categorized into two forms: Narrow AI and AGI. The latter
                        is purely theoretical; AGI describes a program’s ability to be applied to virtually any
                        scenario, capable of adapting to the problem presented to it. Narrow AI describes instances of
                        adaptable programs created for very specific scenarios - a chatbot, for example. As such, we’ll
                        be dealing with Narrow AI when discussing its application into military endeavors.</p>
                    <h3>Machine Learning</h3>
                    <p>Machine Learning is one of the most fundamental types of AI generally used today. Machine
                        Learning is used to complete minimally difficult tasks humans are also capable of; albeit at a
                        faster pace than us. When given a set of data, an AI can cluster the items into groups, seek out
                        and detect anomalies, identify association between variables, and even - given time - eliminate
                        redundant/repetitive variables. Machine Learning AIs can fall into several subsets, including
                        supervised, semi-supervised and unsupervised learning. This describes the extent at which humans
                        aid in the AI’s ‘learning’ process. </p>
                    <p>For example, the AI could be given labeled data, or it could be given unlabeled data and required
                        to draw its own conclusions. Today, Machine Learning is most used in tasks such as detecting
                        instances of fraud/spam, personalizing social media feeds, and even to prioritize messages and
                        emails based on previous interactions. This in mind, Machine Learning is no doubt used in
                        hundreds of targeting systems and navigation tools for the military, even if most of these end
                        up undocumented.</p>
                    <h3>Lethal Autonomous Weapons (LAWs)</h3>
                    <p>LAWs are likely the most common militaristic application of AI. LAWs are capable of independent
                        target-seeking and engaging. Although the majority of advanced LAWs today are Anti-Airdevices,
                        LAWs may also operate on water or in the air.</p>
                    <p>Examples of currently operating LAWs include Israeli ‘Trophies’ as well as the US-based ‘Patriot’
                        missile systems. Currently, most LAWs are made use of defensively - however, they hold huge
                        potential for offensive use, and so must be regulated before they become mainstream.</p>
                    <h3>Militarization</h3>
                    <p>Militarization is the cultural, symbolic, and material preparation for war. As recent research in
                        anthropology has shown, militarization and the presence of state militaries influences much of
                        the ‘everyday life’ in many societies and cultures around the world, both explicitly and subtly.
                        Most importantly, militarization is an intentional process, something a state or group must set
                        out to do; as Margaret Mead wrote, war – and in this case, the preparation for war – is not a
                        ‘biological necessity’. Rather, militarization and the development of military institutions are
                        explicit projects, but are often cloaked in discourses of biological inevitability.
                        Militarization programs often trade in and promote ideas about innate violence and the
                        naturalness of military values.</p>
                </div>
            </section>
            <!-- ======= General Overview ======= -->
            <section id='general-overview'>
                <div class='container-xl'>
                    <h2>General Overview</h2>
                    <p>Artificial Intelligence (AI) has the potential to improve the health and well-being of
                        individuals, communities, and states, and help meet the UN’s Sustainable Development Goals.
                        However, certain uses of AI could also undermine international peace and security by raising
                        concerns about safety and security of the technology, accelerating the pace of armed conflicts,
                        or loosening human control over the means of war. </p>
                    <h3>The Danger of Human Absence</h3>
                    <p> The political and social implications of AI are very rarely considered - discussions usually
                        fall under scientific and technological headings. Although AI is a very exciting tool for
                        humanity, with potentially limitless benefits, it’s important to think of what that means for
                        us. What exactly does a world where humans don’t make decisions look like? </p>
                    <p>Releasing any form of independently capable machines into battle is a huge risk. Today, gun
                        control in the US is a mainstream topic: it’s argued that guns don’t belong in the hands of
                        untrained citizens. How then, would we feel safe putting weapons in the hands of apathetic,
                        emotionless machinery? Removing our involvement completely is a concept which shouldn’t be in
                        debate - humans should always have the final say. In fact, in a 2021 report, Michelle Bachelet,
                        UN High Commissioner for Human Rights, affirmed this sentiment - warning that applying
                        Artificial Intelligence to areas involving human rights could ‘have negative, even catastrophic
                        effects’.</p>
                    <h3>Potential Risks of Military Applications of Artificial Intelligence</h3>
                    <p>The risks of introducing artificial intelligence into national militaries are not small. Lethal
                        autonomous weapon systems (LAWS) receive popular attention because such systems are easily
                        imagined and raise important security, legal, philosophical, and ethical questions. Multiple
                        other risks from military applications of AI that pose challenges to international peace and
                        security can be identified. Militaries are likely to use AI to assist with decision making. This
                        may be through providing information to humans as they make decisions, or even by taking over
                        the entire execution of decision-making processes. This may happen, for example, in
                        communications-denied environments or in environments such as cyberspace, in which action
                        happens at speeds beyond human cognition. While this may improve a human operator’s or
                        commander’s ability to exercise direct command and control over military systems, it could also
                        have the opposite effect. AI affords the construction of complex systems that can be difficult
                        to understand, creating problems of transparency and of knowing whether the system is performing
                        as expected or intended. Where transparency is sufficiently prioritized in AI design, this
                        concern can be reduced. Where it is not, it becomes possible that errors in AI systems will go
                        unseen—whether such errors are accidental or caused deliberately by outside parties using
                        techniques like hacking or data poisoning.</p>
                    <p>One can wonder whether AI can be used effectively to hack, distort, or corrupt the functions of
                        command-and-control structures, including early warning systems for nuclear weapons.</p>
                    <p>Increasing complexity could make AI systems harder to understand and, therefore, encourage the
                        use of trust rather than transparency. Increased trust means that errors and failures are even
                        less likely to be detected. </p>
                    <p>The potential for lone actors to use AI-enabled tools, these concerns are moderated by their
                        inability to apply them at large scale. More problematic is the potential for an arms race on an
                        international level. The potential ill effects of AI arms racing are threefold. First, arms race
                        dynamics have in the past led to high levels of government spending that were poorly prioritized
                        and inefficient and an increase in tensions. Second, arms racing can generate an insecurity
                        spiral, with certain nations perceiving others’ pursuit of new technolgies as threatening.
                        Third, the development of AI tools for use by national militaries is in a discovery phase, with
                        government and industry alike working to find areas for useful application. Competition at the
                        industry and state levels might, therefore, incentivize fast deployment of new and potentially
                        insufficiently tested capabilities, as well as hiding of national AI priorities and progress.
                        These characteristics of arms racing—high rates of investment, a lack of transparency, mutual
                        suspicion and fear, and a perceived incentive to deploy first—heighten the risk of avoidable or
                        accidental conflict. </p>
                    <h3>Potential Benefits of Military Application of Artificial Intelligence </h3>
                    <p>Although AI, in its current juvenile state, poses immense threats if applied irresponsibly and
                        hastily, there are also many benefits to consider. Chief among these is the concept of fully
                        automated warfare - and the elimination of human involvement from conflicts. In fact, in
                        situations such as American involvement in Middle-Eastern conflicts, the use of unmanned and
                        automated weapons have seen immense backing for this reason. Why send one’s own men and women
                        overseas to fight, when a nation could simply send machines with minimal risk?</p>
                    <p>Although flawed, this is a very valid argument. Countless deaths in conflicts worldwide could be
                        prevented in the future through mutual usage of autonomous weapons by both parties. Entire wars
                        and battles could end with not a single drop of human blood spilled. Of course, there then
                        arises the issue of a gigantic global imbalance of power, but it stands to reason that economic
                        superpowers are aiming for military dominance regardless of AI involvement.</p>
                    <p>For national militaries, AI has broad potential beyond weapons systems. Often referred to as a
                        tool for jobs that are “dull, dirty, and dangerous,” AI applications offer a means to avoid
                        putting human lives at risk or assigning humans to tasks that do not require the creativity of
                        the human brain. AI systems also have the potential to reduce costs in logistics and sensing and
                        to enhance communication and transparency in complex systems, if that is prioritized as a design
                        value. In particular, as an information communication technology, AI might benefit the
                        peacekeeping agenda by more effectively communicating the capacities and motivations of military
                        actors.</p>
                    <h3>Applications of AI in the Military</h3>
                    <p>The military use of drones dates back to the reactions to the 9/11 attacks, specifically to
                        October 2002, with a huge increase during the Obama administrations.We know that the United
                        States uses them in Afghanistan, Yemen, Iraq, Pakistan and Somalia, and that purchases of drones
                        or research to obtain them is steadily on the rise. In fact, between 30 and 76 states already
                        possess drone technology.</p>
                    <p>Some sources date the military use of drones as weapons directly for attack to 2001, to the war
                        in Afghanistan, and it is estimated that some 40 states now have drones or have decided to get
                        them in the short term. With respect to the United States, although drones went hand in hand
                        with the two terms of George Bush Jr. (particularly in Afghanistan and its eastern border), with
                        Barack Obama drone use has risen substantially (in terms of quantity, of the number of civilian
                        casualties caused, etc.) and has been extended to other scenarios (Pakistan, Yemen and even
                        Somalia). As a result, from 2004 to 2013, drones killed 3,460 people in Pakistan alone, at least
                        35% of which can only be described as ‘innocent civilians’, according to Pakistani sources
                        (which have their own criteria for these cases on who is and who is not “civilian”). </p>
                    <p>Drone strikes have had a serious radicalizing impact on public opinion in the country, with a
                        serious shift to the right in the last few years. The cricketer turned politician, Imran Khan,
                        has used these attacks as examples of American hubris, blaming them for massive collateral
                        damage and death of innocent civilians. Khan believes that the use of American unmanned aerial
                        vehicles has not been very effective, as the situation in Afghanistan and Pakistan is far worse
                        than it was when the strikes were initially employed in 2004. </p>
                    <p>Drones are theoretically used so that troops do not have to be put on the ground to enter and
                        occupy the land and search for and pursue the enemy, with results that are in theory more
                        efficient. As a result, fewer casualties of one’s own and a maximisation of enemy casualties
                        takes place. Israel’s armed and security forces have already integrated these many uses of
                        drones: especially to watch, follow, identify and conduct deadly attacks with other means like
                        air-to-ground missiles in places like Gaza and areas of the West Bank.</p>
                    <p>Ukraine’s use of Western information technology, including artificial intelligence (ai) and
                        autonomous surveillance systems, has also had a powerful, if less visible, impact on Russian
                        forces and has changed the way Ukrainian troops target the enemy, and even the nature of
                        counter-terrorism.</p>
                    <p>When Russia invaded last February, its air campaign initially looked to be a central part in
                        Russia’s war strategy: Russia sent waves of pilots in advanced fighter jets to bomb Ukraine. The
                        near universal assumption was Russia's powerful air force would quickly overwhelm Ukraine's much
                        smaller force and establish air superiority.</p>
                    <p>However, Russia is relying on missiles and drones, which are much cheaper and easier to
                        replace.As this is a war where it's much more sustainable to use <strong>unmanned</strong>
                        assets, whether those unmanned assets are drones or missiles.</p>
                    <p>Drones have been an integral part of Ukraine’s war strategy. For instance, the January 2nd
                        Ukrainian drone attack on Makiivka, a town in the partially Russian-occupied eastern Donetsk
                        region saw emergency crews sifting through the rubble of a building struck by Ukrainian rockets,
                        killing at least 63 Russian soldiers. </p>
                </div>
            </section>
            <!-- ======= Major Parties Involved ======= -->
            <section id='mp-involved'>
                <div class='container-xl'>
                    <h2>Major Parties Involved</h2>
                    <h3>United Nations Office for Disarmament Affairs (UNODA)</h3>
                    <p>Launched in 1998 as part of former Secretary General Kofi Annan’s UN reform plan, the UNODA aims
                        to achieve the ‘ultimate goal of general and complete disarmament’. Its mandate is derived from
                        the 10th Special Session of the General Assembly, the first disarmament-centered GA session.</p>
                    <p>The UNODA works alongside other UN bodies such as the First General Assembly and the Disarmament
                        Commission. Through diplomacy and transparency, the UNODA consistently sets the golden standard
                        for disarmament efforts on a regional and international scale.</p>
                    <p>As well as encouraging disarmament, the UNODA also serves as an impartial information hub on
                        disarmament issues. It spreads objective and up-to-date information to UN Member States, as well
                        as governmental institutions, the general public/media, and NGOs.</p>
                    <h3>Key Manufacturers</h3>
                    <p>Throughout the arguments for and against the implementation of AI in the military, it's essential
                        to Include prominent and key manufacturers in this field.</p>
                    <p>In the United States, market leaders involved with the military include Lockheed Martin, L3Harris
                        Technologies and Northrop Grumman.</p>
                    <p>UK-based BAE Systems plc is Europe’s biggest defense contractor, and the seventh largest in the
                        world as of 2021. Rafael Advanced Defense Systems, the Israel-based manufacturer, was Israel’s
                        Defense R&D Laboratory before it became a limited company.</p>
                    <h3>Leaders in Innovation</h3>
                    <p>While they may not directly cooperate with international militaries, tech giants such as Google,
                        Amazon and IBM are all major parties in this discussion. Google’s DeepMind AI has been
                        groundbreaking for research and development in AI worldwide, becoming the first computer to beat
                        human champions in games such as Chess, Go and Jeopardy.</p>
                    <p>Meanwhile, Amazon Web Services (AWS) consistently makes use of its top-of-the-line Machine
                        Learning and AI systems to serve personalized advertisements and even develop further AI
                        solutions. Neglecting market leaders in political discussions is common, but in such a critical
                        situation, it’s essential to consider how AI’s transformative potential can even shape the
                        market.</p>
                </div>
            </section>
            <!-- ======= Timeline of Key Events ======= -->
            <section id='timeline-key-events'>
                <div class='container-xl'>
                    <h2></h2>
                </div>
            </section>
            <!-- ======= un ======= -->
            <section id=un>
                <div class='container-xl'>
                    <h2>UN involvement, Relevant Resolutions, Treaties and Events</h2>
                    <ul>
                        <li>Meeting of the High Contracting Parties to the CCW, 13 November 2019, (CCW/MSP/2019/9- Annex
                            III)</li>
                        <li>Impact of rapid technological change on the achievement of the Sustainable Development
                            Goals, 22 December 2017, (A/RES/72/242)</li>
                        <li>Role of science and technology in the context of international security and disarmament, 4
                            December 2017, (A/RES/72/28)</li>
                        <li>Letter from the Panel of Experts on Libya to the Secretary General, 8 March 2021,
                            (S/2021/229) </li>
                    </ul>
                </div>
            </section>
            <!-- ======= Previous Attempts to solve the issue ======= -->
            <section id=previous-attempts>
                <div class='container-xl'>
                    <h2>Previous Attempts to Solve the Issue</h2>
                    <h3>United Nations’ Convention on Conventional Weapons (CCW)</h3>
                    <p>In its efforts to gain a handle on growing AI fears, the UN has focused its efforts to regulate
                        Artificial Intelligence through its Convention on Conventional Weapons.</p>
                    <p>The CCW is the perfect stage upon which the humanitarian benefits and risks of AI can be
                        considered. Members of the CCW are very varied and balanced, bringing together various different
                        perspectives on the issue. Every country with notably functioning AI weaponry is a High
                        Contracting Member, and so are several independent institutions and organizations such as the
                        Human Rights Watch and the International Committee of the Red Cross. Furthermore, the inclusion
                        of young entrepreneurs and prominent business and industry leaders aids in combating the
                        exclusion of the industry from ethical debate, as there are many stakeholder companies majorly
                        involved.</p>
                    <p>Although the CCW has not yet produced a complete, substantial treaty signed by its members, it
                        has served to foster constructive debate on the legal and ethical aspects of Artificial
                        Intelligence. </p>
                    <p>The CCW’s Group of Governmental Experts (GGE) meet annually, with a large-scale CCW Review
                        meeting every five years.</p>
                </div>
            </section>
            <!-- ======= Possible Solutions ======= -->
            <section id='solutions'>
                <div class='container'>
                    <h2>Possible Solutions </h2>
                    <h3>Enforcing Human Involvement</h3>
                    <p>As previously stated, AI is in its juvenile state. However, it is also no longer a theoretical
                        far-off problem, so we must now rapidly develop means of controlling and regulating the forms AI
                        can take shape in.</p>
                    <p>After World War 1, the international community banded together to utterly ban biochemical warfare
                        - an international agreement of this sort is now necessary. At this time, it is very improbable
                        if not impossible to achieve a full global ban on the militarization of AI. However, it is
                        plausible to totally and completely ensure that there must remain human involvement. </p>
                    <p>A treaty, likely UN-formed, should be written on the issue, and the international community
                        should halt all instances of totally independent machine weaponry - at least for now. There yet
                        remains the possibility in the future of perfecting AI to the point where these concerns no
                        longer exist.</p>
                    <h3>Technology Controls</h3>
                    <p>Military technologies can be controlled or restricted at a number of stages along their
                        development cycle. Nonproliferation regimes aim to limit access to the underlying technology
                        behind certain weapons. The Nuclear Non-Proliferation Treaty, for example, aims to prevent the
                        spread of nuclear weapons, promote cooperation on peaceful uses of nuclear energy, and further
                        the goal of nuclear disarmament. Some weapons bans, like those on land mines and cluster
                        munitions, allow access to the technology but prohibit developing, producing, or stockpiling the
                        weapon. Other bans only apply to use, sometimes prohibiting use entirely or proscribing only
                        certain kinds of uses of a weapon. Finally, arms-limitation treaties permit use but limit the
                        quantities of certain weapons states can have in peacetime. Updating pre-existing legislation is
                        animperative. For instance, old arms control convention could be usedsuch as the Convention on
                        Certain Conventional Weapons. Known during the Cold War as the “Inhumane Weapons Convention,” it
                        focused on conventional weapons deemed to have indiscriminate effects, adding an additional
                        protocol on the use of drones could be useful. </p>
                    <h3>Building Safe and Secure AI Systems</h3>
                    <p>Ultimately, the most powerful tool states have at their disposal for mitigating the risk of
                        military AI systems comes from building safe and secure AI systems themselves. Militaries have
                        an incentive to keep their systems under effective operational control. AI systems that slip out
                        of human control could not only cause an accident, possibly harming third parties, but are also
                        not very useful to the military that deploys them. Military systems that may not work or could
                        be hacked by the enemy are not very useful or valuable. Conducting better tests and evaluation
                        and maintaining humans in overall operational control of the system through a human machine
                        centaur command-and-control model may be the best approach for mitigating the risks of military
                        AI.</p>
                </div>
            </section>
            <!-- ======= Bibliography ======= -->
            <section id='bibliography'>
                <div class='container-xl'>
                    <h2>Bibliography</h2>
                    <ul>
                        <li>“Artificial Intelligence in Military Market Size & Share | Industry Report, 2020-2025 |
                            MarketsandMarketsTM.” MarketsandMarkets - Revenue Impact & Advisory Company | Market
                            Research Reports | Business Research Insights, hBurns. “What Is Machine Learning and Why Is
                            It Important?” SearchEnterpriseAI,</li>
                        <li>TechTarget, 30 Mar. 2021,
                            https://www.techtarget.com/searchenterpriseai/definition/machine-learning-ML#:~:text=Machine%20le
                            arning%20(ML)%20is%20a,to%20predict%20new%20output%20values. </li>
                        <li>Cuthbertson, Anthony. “China Achieves ‘Brain-Scale’ AI with Latest Supercomputer |The
                            Independent.” The Independent, The Independent, 22 June 2022,
                            https://www.independent.co.uk/tech/china-ai-brain-supercomputer-sunway-b2106730.html.</li>
                        <li>Nations, United. “The Role of the United Nations in Addressing Emerging Technologies in the
                            Area of Lethal Autonomous Weapons Systems | United Nations.” United Nations,
                            https://www.un.org/en/un-chronicle/role-united-nations-addressing-emerging-technologies-area-lethal-a
                            utonomous-weapons. </li>
                        <li>“The Convention on Certain Conventional Weapons – UNODA.” Welcome to the United Nations,
                            https://www.un.org/disarmament/the-convention-on-certain-conventional-weapons/.</li>
                        <li>“THE KARGU-2 AUTONOMOUS ATTACK DRONE: LEGAL & ETHICAL DIMENSIONS.” Lieber Institute West
                            Point, 10 June 2021,
                            https://lieber.westpoint.edu/kargu-2-autonomous-attack-drone-legal-ethical/.</li>
                        <li>“UN AI Actions - AI for Good.” AI for Good,
                            https://www.facebook.com/AIforGood,https://aiforgood.itu.int/about-ai-for-good/un-ai-actions/.
                        </li>
                        <li>“193 Countries Adopt First-Ever Global Agreement on the Ethics of Artificial Intelligence
                        </li>
                        <li>| | UN News.” UN News, 25 Nov. 2021, https://news.un.org/en/story/2021/11/1106612.“Lethal
                            Autonomous Weapons Systems: Recent Developments - Lawfare.” Lawfare, 7 Mar. 2019,
                            https://www.lawfareblog.com/lethal-autonomous-weapons-systems-recent- developments. </li>
                        <li>McCormick, Ty. “Lethal Autonomy: A Short History – Foreign Policy.” Foreign Policy, Foreign
                            Policy, 24 Jan. 2014, https://foreignpolicy.com/2014/01/24/lethal-autonomy-a-short-history/.
                        </li>
                        <li>Nations, United. “Towards an Ethics of Artificial Intelligence | United Nations.” United
                            Nations, https://www.un.org/en/chronicle/article/towards-ethics-artificial-intelligence.
                        </li>
                        <li>Roth, Marcus. “AI in Military Drones and UAVs – Current Applications | Emerj Artificial
                            Intelligence Research.” Emerj Artificial Intelligence Research, Emerj, 30 Jan. 2019,
                            https://emerj.com/ai-sector-overviews/ai-drones-and-uavs-in-the-military-current-applications/.
                        </li>
                        <li><a href="https://stanleycenter.org/publications/militarization-of-artificial-intelligence/#:~:text=Militaries%20are
                            %20developing%20systems%20that,control%2C%20or%20even%20lethal%20force">
                                https://stanleycenter.org/publications/militarization-of-artificial-intelligence/#:~:text=Militaries%20are
                                %20developing%20systems%20that,control%2C%20or%20even%20lethal%20force.</a></li>
                    </ul>
                </div>
            </section>
            <!-- ======= Appendix ======= -->
            <section id=>
                <div class='container-xl'>
                    <h2>Appendix</h2>
                    <ul>
                        <li>https://www.un.org/disarmament/the-convention-on-certain-conventional-weapons/background-on-laws-in-the-ccw/
                            - Relevant Publications regarding LAWs and the results of CCW meetings </li>
                        <li> https://www.un.org/disarmament/the-militarization-of-artificial-intelligence/ - UN paper on
                            militarization of AI</li>
                        <li>https://drive.google.com/drive/folders/1TujK1Fqz2o9gvY_XqPpTPtpzUpujCNzT</li>
                        <li>https://www.icip.cat/perlapau/en/article/the-military-use-of-drones-and-their-use-in-acts-of-war
                        </li>
                        <li>https://www.economist.com/the-economist-explains/2022/10/19/will-russias-drone-attacks-change-thewar-in-ukraine?ppccampaignID=&ppcadID=&ppcgclID=&utm_medium=cpc.adword.pd&utm_source=
                            google&ppccampaignID=18151738051&ppcadID=&utm_campaign=a.22brand_pmax&utm_content=c
                            onversion.direct-response.anonymous&gclid=Cj0KCQjw2cWgBhDYARIsALggUhpxUIpyC9jNfWG6
                            GbcMCj4USVdNDEA-lB8siVgHo4qAQC_QwFcFO-YaAp0FEALw_wcB&gclsrc=aw.ds</li>
                        <li>https://www.pbs.org/newshour/world/russia-shaken-by-ukrainian-strike-may-step-up-drone-use
                        </li>
                    </ul>
                </div>
            </section>
        </article>
    </main><!-- End Main -->
    <footer>
    </footer><!-- End Footer -->
    <!-- Vendor js file -->
    <script src="assets/vendor/bootstrap/js/bootstrap.min.js"></script>
    <!-- Main js File -->
    <script src="assets/js/main.js"></script>
</body>

</html>